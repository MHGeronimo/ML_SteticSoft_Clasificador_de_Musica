# src/pages/2_An√°lisis_del_Modelo.py (Versi√≥n actualizada para el modelo mejorado)

import streamlit as st
import pandas as pd
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from pathlib import Path

# --- MANEJO DE RUTAS ROBUSTO ---
# Funciona correctamente desde la subcarpeta /pages
ROOT_DIR = Path(__file__).parent.parent.parent
# --- CAMBIO 1: Apuntar a la nueva carpeta de modelos ---
MODELS_DIR = ROOT_DIR / "models_mejorados"
DATA_DIR = ROOT_DIR / "data"

# --- FUNCIONES ---
@st.cache_resource
def load_artifacts():
    # --- CAMBIO 2: Cargar los NUEVOS archivos .joblib ---
    model = joblib.load(MODELS_DIR / 'modelo_mejorado.joblib')
    label_encoder = joblib.load(MODELS_DIR / 'encoder_mejorado.joblib')
    scaler = joblib.load(MODELS_DIR / 'scaler_mejorado.joblib') # Tambi√©n cargamos el nuevo scaler
    return model, scaler, label_encoder

@st.cache_data
def get_test_data(_scaler, _label_encoder): # Pasamos scaler y encoder para consistencia
    """
    Carga el NUEVO dataset, lo procesa y devuelve los datos de prueba.
    """
    # --- CAMBIO 3: Cargar el NUEVO archivo CSV ---
    df = pd.read_csv(DATA_DIR / 'features_59_char_3_sec.csv')
    
    # El nuevo CSV no tiene la columna 'length', as√≠ que la quitamos del drop
    X = df.drop(['filename', 'label'], axis=1)
    y = df['label']
    
    # Usamos los artefactos ya cargados para asegurar consistencia
    y_encoded = _label_encoder.transform(y)
    X_scaled = _scaler.transform(X)

    _, X_test, _, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)
    return X_test, y_test

# --- CARGA ---
try:
    model, scaler, label_encoder = load_artifacts()
    X_test, y_test = get_test_data(scaler, label_encoder)
    LOAD_SUCCESS = True
except FileNotFoundError:
    st.error("Error al cargar archivos. Aseg√∫rate de que la carpeta 'models_mejorados' y el archivo 'features_59_char_3_sec.csv' existan.")
    LOAD_SUCCESS = False

# --- INTERFAZ ---
st.set_page_config(page_title="An√°lisis del Modelo", page_icon="üìä")
st.title("üìä An√°lisis de Rendimiento del Modelo v2")
st.write("Aqu√≠ evaluamos el rendimiento de nuestro `RandomForestClassifier` **mejorado** (entrenado con 59 caracter√≠sticas).")

if LOAD_SUCCESS:
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    st.header(f"Precisi√≥n (Accuracy) del Modelo")
    st.metric(label="Accuracy", value=f"{accuracy:.2%}")
    st.progress(accuracy)

    st.header("Reporte de Clasificaci√≥n")
    st.write("Muestra las m√©tricas de `precision`, `recall` y `f1-score` para cada g√©nero.")
    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose())

    st.header("Matriz de Confusi√≥n")
    st.write("Esta matriz visualiza en qu√© g√©neros se confunde m√°s el modelo. La diagonal principal representa las predicciones correctas.")
    
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, ax=ax)
    plt.xlabel('Predicci√≥n del Modelo')
    plt.ylabel('G√©nero Real')
    st.pyplot(fig)